{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Activity 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re1qIJYAAVsE",
        "colab_type": "text"
      },
      "source": [
        "# Activity 4. MNIST Hand-written digit classification\n",
        "\n",
        "### **2019/11/21 CoE 202 Fall**<br/>\n",
        "\n",
        "**Professor: Yong Hoon, Lee**</br>\n",
        "\n",
        "**TA:Beomgu Kang, Seungjun moon**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iii6-C0YAVsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "835013a8-61f7-41e8-87e1-1f28604c8e5a"
      },
      "source": [
        "from __future__ import print_function\n",
        "from collections import namedtuple\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from tensorflow.python.training import moving_averages\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF-EbqXXAVsI",
        "colab_type": "text"
      },
      "source": [
        "## 1. Prepare the data\n",
        "### <a href=http://yann.lecun.com/exdb/mnist/>MNIST dataset</a>\n",
        "The MNIST has a training set of 55,000 examples, a validation set of 5,000 examples and a test set of 10,000 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmcTChfSAVsJ",
        "colab_type": "code",
        "outputId": "b2079412-d1db-4f57-c607-21c5717d40c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "mnist = input_data.read_data_sets('./data/', one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting ./data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting ./data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvJbNDKuAVsL",
        "colab_type": "text"
      },
      "source": [
        "Load the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0lZ8NBcAVsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = mnist.train.images[:1000]\n",
        "train_labels = mnist.train.labels[:1000]\n",
        "train_images = train_images.reshape([-1, 28, 28, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDWxwqUFAVsN",
        "colab_type": "text"
      },
      "source": [
        "Load the validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBvaFbp3AVsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_images = mnist.validation.images\n",
        "val_labels = mnist.validation.labels\n",
        "val_images = val_images.reshape([-1, 28, 28, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCSYM9SrAVsP",
        "colab_type": "text"
      },
      "source": [
        "Plot the 1st hand-written digit and its one-hot label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FeHejL9AVsQ",
        "colab_type": "code",
        "outputId": "b7aba754-1cbe-4154-b02a-647e68f23c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "plt.imshow(train_images[0,:,:,0], cmap='Greys')\n",
        "print(\"\\nOne-hot labels for this image:\")\n",
        "print(train_labels[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "One-hot labels for this image:\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXMfVOQuAVsS",
        "colab_type": "text"
      },
      "source": [
        "## 2. Build a graph for VGGNet (Oxford, 2014)\n",
        "Very Deep Convolutional Networks for Large-scale image recognition\n",
        "https://arxiv.org/abs/1409.1556\n",
        "\n",
        "<img src=\"img/fig2.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT8_jNCpAVsT",
        "colab_type": "text"
      },
      "source": [
        "### Set hyperparameters\n",
        "- ***log_dir*** : Directory name to save models\n",
        "- ***n_epochs*** : Maximun training epoch\n",
        "- ***n_outputs*** : The number of classes for labels\n",
        "- ***init_lr*** : Learning rate for gradient descent\n",
        "- ***l2_lambda*** : regularization parameter\n",
        "- ***batch_size*** : The number of images to update paramerters once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlE-h0yVAVsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = 'logs/'\n",
        "n_epochs = 20\n",
        "n_outputs = 10\n",
        "init_lr = 0.01\n",
        "batch_size = 100\n",
        "l2_lambda = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOUINJj-AVsV",
        "colab_type": "text"
      },
      "source": [
        "### Placeholder for learning rate, input images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aA8tlbnAVsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrn_rate = tf.placeholder(tf.float32, shape=(), name='lrn_rate')\n",
        "images = tf.placeholder(tf.float32, shape=(None, 28, 28, 1), name='images')\n",
        "labels = tf.placeholder(tf.int32, shape=(None), name='labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1FekGzAAVsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vggnet(images, labels=None):\n",
        "    vggnet_conv = partial(tf.layers.conv2d, kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_lambda), padding=\"SAME\")\n",
        "    \n",
        "    ''' 1st conv. '''\n",
        "    x = vggnet_conv(images, filters=16, kernel_size=7, strides=[1,1])  # 7x7 filter, # of filters: 16, stride: 1\n",
        "    #print(x)\n",
        "    x = tf.layers.batch_normalization(x, name='bn1')                   # batch normalization\n",
        "    x = tf.nn.relu(x)                                                  # ReLU activation\n",
        "    \n",
        "    ''' 2nd conv.'''\n",
        "    x = vggnet_conv(x, filters=16, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 16, stride 1\n",
        "    x = tf.layers.batch_normalization(x, name='bn2')                   # batch normalization\n",
        "    x = tf.nn.relu(x)                                                  # ReLU activation\n",
        "    x = tf.layers.average_pooling2d(x, pool_size=[2,2], strides=[2,2]) # 2x2 average pooling, stride: 2\n",
        "    \n",
        "    ''' 3rd conv. '''\n",
        "    x = vggnet_conv(x, filters=32, kernel_size=3, strides=[1, 1])      # 3x3 filter, # of filters: 32, stride: 1\n",
        "    x = tf.layers.batch_normalization(x, name='bn3')                   # batch normalization\n",
        "    x = tf.nn.relu(x)                                                  # ReLU activation\n",
        "    \n",
        "    ''' 4th conv. '''\n",
        "    x = vggnet_conv(x, filters=32, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 32, stride 1\n",
        "    x = tf.layers.batch_normalization(x, name='bn4')                   # batch normalization\n",
        "    x = tf.nn.relu(x)                                                  # ReLU activation\n",
        "    x = tf.layers.average_pooling2d(x, pool_size=[2,2], strides=[2,2]) # 2x2 average pooling stride 2\n",
        "    \n",
        "    ''' 5th conv. '''\n",
        "    x = vggnet_conv(x, filters=64, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 64, stride: 1\n",
        "    x = tf.layers.batch_normalization(x, name='bn5')                   # batch normalization\n",
        "    x = tf.nn.relu(x)                                                  # ReLU activation\n",
        "    \n",
        "    ''' 6th conv. '''\n",
        "    x = vggnet_conv(x, filters=64, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 64, stride: 1\n",
        "    x = tf.layers.batch_normalization(x, name='bn6')                   # batch normalization\n",
        "    x = tf.nn.relu(x)                                                  # ReLU activation\n",
        "    \n",
        "    img_feat = tf.reduce_mean(x, [1, 2])                               # Global average pooling\n",
        "    return img_feat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ2O3pJlBRDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_network(images, labels=None):\n",
        "    vggnet_conv = partial(tf.layers.conv2d, kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_lambda), padding=\"SAME\")\n",
        "    ''' 1st conv. '''\n",
        "    x = vggnet_conv(images, filters=16, kernel_size=3, strides=[1,1])  # 3x3 filter, # of filters: 16, stride: 1\n",
        "    x = tf.layers.batch_normalization(x, name='bn1')                   # batch normalization\n",
        "    x = tf.nn.relu(x)                                                  # ReLU activation\n",
        "    ''' 2nd conv.'''\n",
        "    x2 = vggnet_conv(x, filters=16, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 16, stride 1\n",
        "    x2 = tf.layers.batch_normalization(x2, name='bn2')                   # batch normalization\n",
        "    x2 = tf.nn.relu(x2)                                                  # ReLU activation\n",
        "    x2 = tf.layers.average_pooling2d(x2, pool_size=[2,2], strides=[2,2]) # 2x2 average pooling, stride: 2\n",
        "    ''' 3rd conv. '''\n",
        "    x1 = vggnet_conv(x, filters=16, kernel_size=3, strides=[2, 2])      # 3x3 filter, # of filters: 32, stride: 2\n",
        "    x1 = tf.layers.batch_normalization(x1, name='bn3')                   # batch normalization\n",
        "    x1 = tf.nn.relu(x1)                                                  # ReLU activation\n",
        "    \n",
        "    #Elementwise-sum: tf.add()\n",
        "    x3=tf.add(x1,x2)\n",
        "\n",
        "    ''' 4th conv. '''\n",
        "    x5 = vggnet_conv(x3, filters=16, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 16, stride 1\n",
        "    x5 = tf.layers.batch_normalization(x5, name='bn4')                   # batch normalization\n",
        "    x5 = tf.nn.relu(x5)                                                  # ReLU activation\n",
        "    \n",
        "    #Concatenate: tf.concat()\n",
        "    x6=tf.concat([x3, x5], 1)\n",
        "    #x6=tf.concat([x3, x5], 0)\n",
        "\n",
        "    ''' 5th conv. '''\n",
        "    x7 = vggnet_conv(x6, filters=32, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 32, stride: 1\n",
        "    x7 = tf.layers.batch_normalization(x7, name='bn5')                   # batch normalization\n",
        "    x7 = tf.nn.relu(x7)                                                  # ReLU activation\n",
        "    \n",
        "    img_feat = tf.reduce_mean(x7, [1, 2])                               # Global average pooling\n",
        "    return img_feat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dz9BFJOAVsZ",
        "colab_type": "text"
      },
      "source": [
        "### Build a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYp4HfqTAVsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "with tf.variable_scope('embed') as scope:\n",
        "  #using our simple model\n",
        "  feats = simple_network(images)\n",
        "  #feats = vggnet(images)\n",
        "\n",
        "## Reshape\n",
        "#feats = tf.reshape(feats, [batch_size, 64])\n",
        "feats = tf.reshape(feats, [batch_size, 32])\n",
        "    \n",
        "## Logits\n",
        "logits = tf.layers.dense(feats, n_outputs, kernel_initializer=tf.uniform_unit_scaling_initializer(factor=2.0), \n",
        "                                               kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_lambda))\n",
        "\n",
        "## Evaluation\n",
        "correct = tf.nn.in_top_k(logits, labels, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "## SOFTMAX\n",
        "preds = tf.nn.softmax(logits)\n",
        "\n",
        "## Cost function\n",
        "cent = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
        "cost_cls = tf.reduce_mean(cent, name='cent')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hau3QzcFAVsc",
        "colab_type": "text"
      },
      "source": [
        "### L2 regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkMgF0QPAVsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
        "cost = tf.add_n([cost_cls] + reg_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxEL6aJ7AVse",
        "colab_type": "text"
      },
      "source": [
        "### Momentum optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we7_C_syAVsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr  = tf.train.exponential_decay(init_lr, global_step, 1000, 0.8, staircase = True) # learning rate decay\n",
        "optimizer = tf.train.MomentumOptimizer(lr, 0.9, use_nesterov=True)                  # Momentum optimizer\n",
        "train_op = optimizer.minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBr9sjtMAVsh",
        "colab_type": "text"
      },
      "source": [
        "# 3. Train a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccD7l0eAVsh",
        "colab_type": "text"
      },
      "source": [
        "### Create a session and initialize parameters\n",
        "Tensorflow operations must be executed in the session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzF7krC8AVsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## MAKE SESSION\n",
        "sess = tf.Session()\n",
        "\n",
        "## INITIALIZE SESSION\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0pe2ywLAVsk",
        "colab_type": "text"
      },
      "source": [
        "### Updates parameters with back-propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdNfZCvNAVsl",
        "colab_type": "code",
        "outputId": "142f1f06-f474-4cf4-8703-b632f7945031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "for epoch in range(n_epochs+1):\n",
        "    for iteration in range(mnist.train.num_examples // batch_size):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "        X_batch = X_batch.reshape([-1, 28, 28, 1])\n",
        "        (_, loss, loss_cls, prediction) = sess.run([train_op, cost, cost_cls, preds], \n",
        "                                                    feed_dict={images: X_batch, labels: y_batch})\n",
        "        duration = time.time() - start_time\n",
        "        sec_per_batch = float(duration)\n",
        "    \n",
        "    ## Training accuracy every one epoch\n",
        "    acc_train = accuracy.eval(session=sess, feed_dict={images: X_batch, labels: np.argmax(y_batch, axis=1)})\n",
        "    if epoch % 1 == 0:\n",
        "        print('  [*] TRAINING Iteration %d, Loss: %.4f, Acc: %.4f (duration: %.3fs)'\n",
        "                             % (epoch, loss_cls, acc_train, sec_per_batch))\n",
        "\n",
        "    ## Validation accuracy every 5 epochs\n",
        "    if epoch % 5 == 0:\n",
        "        acc_val = accuracy.eval(session=sess, feed_dict={images: val_images, labels: np.argmax(val_labels, axis=1)})\n",
        "        print('  [*] VALIDATION ACC: %.3f' % acc_val)\n",
        "\n",
        "print('Optimization done.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  [*] TRAINING Iteration 0, Loss: 1.4469, Acc: 0.7200 (duration: 0.006s)\n",
            "  [*] VALIDATION ACC: 0.690\n",
            "  [*] TRAINING Iteration 1, Loss: 0.3460, Acc: 0.9100 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 2, Loss: 0.1320, Acc: 0.9700 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 3, Loss: 0.1753, Acc: 0.9900 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 4, Loss: 0.0842, Acc: 0.9700 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 5, Loss: 0.0627, Acc: 0.9900 (duration: 0.006s)\n",
            "  [*] VALIDATION ACC: 0.970\n",
            "  [*] TRAINING Iteration 6, Loss: 0.1350, Acc: 0.9800 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 7, Loss: 0.1361, Acc: 0.9500 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 8, Loss: 0.1485, Acc: 0.9800 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 9, Loss: 0.1034, Acc: 0.9600 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 10, Loss: 0.0219, Acc: 1.0000 (duration: 0.006s)\n",
            "  [*] VALIDATION ACC: 0.978\n",
            "  [*] TRAINING Iteration 11, Loss: 0.0241, Acc: 1.0000 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 12, Loss: 0.0867, Acc: 0.9900 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 13, Loss: 0.0822, Acc: 1.0000 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 14, Loss: 0.0186, Acc: 1.0000 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 15, Loss: 0.0678, Acc: 0.9900 (duration: 0.006s)\n",
            "  [*] VALIDATION ACC: 0.976\n",
            "  [*] TRAINING Iteration 16, Loss: 0.0960, Acc: 0.9700 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 17, Loss: 0.0502, Acc: 0.9900 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 18, Loss: 0.0133, Acc: 1.0000 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 19, Loss: 0.0273, Acc: 1.0000 (duration: 0.006s)\n",
            "  [*] TRAINING Iteration 20, Loss: 0.0398, Acc: 1.0000 (duration: 0.006s)\n",
            "  [*] VALIDATION ACC: 0.980\n",
            "Optimization done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE9pfB_EAVsn",
        "colab_type": "text"
      },
      "source": [
        "# 4. Test a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If3Ij7YgAVsn",
        "colab_type": "text"
      },
      "source": [
        "### Load the test images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1HEhFSeAVso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "42852b30-0051-452d-ec67-1985353962ab"
      },
      "source": [
        "## READ MNIST INPUTS\n",
        "test_images = mnist.test.images\n",
        "test_labels = mnist.test.labels\n",
        "test_images = test_images.reshape([-1, 28, 28, 1])\n",
        "\n",
        "## Plot the 1st test image and label\n",
        "plt.imshow(test_images[0,:,:,0], cmap='Greys')\n",
        "print(\"\\nOne-hot labels for this image:\")\n",
        "print(test_labels[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "One-hot labels for this image:\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmxjWPZ8AVsp",
        "colab_type": "text"
      },
      "source": [
        "### Check the prediction for the first image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF1SppjaAVsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be24f6c6-9a7d-4873-a6e3-683f7308f12b"
      },
      "source": [
        "prediction = sess.run(preds, feed_dict={images: test_images[0,:,:,0].reshape(1,28,28,1), labels: test_labels[0]})\n",
        "\n",
        "print(\"The prediction of the network is: %d\" % np.argmax(prediction))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction of the network is: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUiMs6yrAVst",
        "colab_type": "text"
      },
      "source": [
        "### Average the accuray for test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAyMOyXtAVst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45eb47d1-6426-4f0c-9de2-18760838873d"
      },
      "source": [
        "test_acc = accuracy.eval(session=sess, feed_dict={images: test_images, labels: np.argmax(test_labels, axis=1)})\n",
        "print('Acc: %.3f' % test_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aixLUn2AVs9",
        "colab_type": "text"
      },
      "source": [
        "## Assignment<hr>\n",
        "### 1. A simple network for MNIST\n",
        "Design the following CNN and apply the CNN to the MNIST dataset.</br>\n",
        "\n",
        "<img src=\"img/fig3.png\">\n",
        "\n",
        "***Hint)*** \n",
        "- Elementwise-sum: tf.add() <br/>\n",
        "- Concatenate: tf.concat()\n",
        "\n",
        "\n",
        "### Submission (Due: Nov. 28 Thu.)\n",
        "Compare the results with that of VGGNET and submit your report by Thursday, November 28 to **\"almona@kaist.ac.kr\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DxoXO_uAVs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}